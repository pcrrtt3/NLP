{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f726280",
   "metadata": {},
   "source": [
    "This notebook applies clustering to our data. \n",
    "\n",
    "Note: should credit https://jonathansoma.com/lede/algorithms-2017/classes/clustering/k-means-clustering-with-scikit-learn/ where this code comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a97a9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e76298d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92bb592",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../../Data/Intermediate Data/final_all_files.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47f6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "707a4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_tokenizer(str_input):\n",
    "    \n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1d5b1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heidiwallace/opt/anaconda3/envs/anlp/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'04</th>\n",
       "      <th>'16</th>\n",
       "      <th>'17</th>\n",
       "      <th>'18</th>\n",
       "      <th>'19</th>\n",
       "      <th>'20</th>\n",
       "      <th>'caus</th>\n",
       "      <th>'d</th>\n",
       "      <th>'em</th>\n",
       "      <th>'god</th>\n",
       "      <th>...</th>\n",
       "      <th>—we</th>\n",
       "      <th>—whether</th>\n",
       "      <th>—you</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "      <th>…a</th>\n",
       "      <th>…hey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.010723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633535</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386666</td>\n",
       "      <td>0.057259</td>\n",
       "      <td>0.057259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 13433 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     '04  '16  '17       '18       '19  '20     'caus        'd  'em  'god  \\\n",
       "0    0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.029532  0.0   0.0   \n",
       "1    0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.023149  0.0   0.0   \n",
       "2    0.0  0.0  0.0  0.008324  0.009893  0.0  0.000000  0.022473  0.0   0.0   \n",
       "3    0.0  0.0  0.0  0.000000  0.000000  0.0  0.006512  0.010723  0.0   0.0   \n",
       "4    0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.028101  0.0   0.0   \n",
       "..   ...  ...  ...       ...       ...  ...       ...       ...  ...   ...   \n",
       "231  0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.0   0.0   \n",
       "232  0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.0   0.0   \n",
       "233  0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.0   0.0   \n",
       "234  0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.0   0.0   \n",
       "235  0.0  0.0  0.0  0.000000  0.000000  0.0  0.000000  0.000000  0.0   0.0   \n",
       "\n",
       "     ...  —we  —whether  —you    ‘         ’         “         ”    …   …a  \\\n",
       "0    ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "1    ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "2    ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "3    ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "4    ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "..   ...  ...       ...   ...  ...       ...       ...       ...  ...  ...   \n",
       "231  ...  0.0       0.0   0.0  0.0  0.633535  0.040705  0.040705  0.0  0.0   \n",
       "232  ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "233  ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "234  ...  0.0       0.0   0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0   \n",
       "235  ...  0.0       0.0   0.0  0.0  0.386666  0.057259  0.057259  0.0  0.0   \n",
       "\n",
       "     …hey  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "..    ...  \n",
       "231   0.0  \n",
       "232   0.0  \n",
       "233   0.0  \n",
       "234   0.0  \n",
       "235   0.0  \n",
       "\n",
       "[236 rows x 13433 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(tokenizer=textblob_tokenizer,\n",
    "                      stop_words='english',\n",
    "                      use_idf=True)\n",
    "matrix = vec.fit_transform(texts)\n",
    "idf_df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "idf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "624ae8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "number_of_clusters=2\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "\n",
    "km.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f2882a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: 's 're n't thi know wa peopl great want said\n",
      "Cluster 1: ’ s veri thi peopl t wa thank ve great\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vec.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :10]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#really need a better tokenizer - will replace - but let's check out what this looks like for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b09a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, everybody. Hello, Orlando. Hello, Sanfo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello, everybody. Hello, Duluth. Hello, Duluth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oh, thank you. Well, we won Pennsylvania last ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you very much. Hello, Newport News. I kn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello Jacksonville, we love Jacksonville, I'm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Good evening. I’d like to provide the American...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>I know your pain. I know your hurt. We had an ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I would like to begin by addressing the heinou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>My fellow Americans,  I want to speak to you t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>My fellow Americans: Four years ago, we launch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  category\n",
       "0    Hello, everybody. Hello, Orlando. Hello, Sanfo...         0\n",
       "1    Hello, everybody. Hello, Duluth. Hello, Duluth...         0\n",
       "2    Oh, thank you. Well, we won Pennsylvania last ...         0\n",
       "3    Thank you very much. Hello, Newport News. I kn...         0\n",
       "4     Hello Jacksonville, we love Jacksonville, I'm...         0\n",
       "..                                                 ...       ...\n",
       "231  Good evening. I’d like to provide the American...         1\n",
       "232  I know your pain. I know your hurt. We had an ...         0\n",
       "233  I would like to begin by addressing the heinou...         0\n",
       "234  My fellow Americans,  I want to speak to you t...         0\n",
       "235  My fellow Americans: Four years ago, we launch...         1\n",
       "\n",
       "[236 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['text'] = texts\n",
    "results['category'] = km.labels_\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e57995ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode rally vs other into new variable\n",
    "data['base'] = np.where(data['event_type']=='rally', 1, 0)\n",
    "\n",
    "results = results.merge(data['base'], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7ba9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode category bc these are pretty close, just opposite assignments\n",
    "results['category2'] = np.where(results['category']==0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac7f5cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9110169491525424"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort of an accuracy calculation - actually pretty\n",
    "sum(results['category2']==results['base']) / results.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e16ab20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heidiwallace/opt/anaconda3/envs/anlp/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'s</th>\n",
       "      <th>’</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      's    ’\n",
       "0    1.0  0.0\n",
       "1    1.0  0.0\n",
       "2    1.0  0.0\n",
       "3    1.0  0.0\n",
       "4    1.0  0.0\n",
       "..   ...  ...\n",
       "231  0.0  1.0\n",
       "232  0.0  0.0\n",
       "233  0.0  0.0\n",
       "234  1.0  0.0\n",
       "235  0.0  1.0\n",
       "\n",
       "[236 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make another df from model with top two featuress\n",
    "vec = TfidfVectorizer(tokenizer=textblob_tokenizer,\n",
    "                      stop_words='english',\n",
    "                      use_idf=True,\n",
    "                      max_features=2)\n",
    "matrix = vec.fit_transform(texts)\n",
    "df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd2630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['apostrophe-s', 'apostrophe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc03e710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['apostrophe-s', 'apostrophe'], dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50a88baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.plot(kind='scatter', x='apostrophe-s', y='apostrophe', alpha=0.2, s=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e505ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#not entirely sure what this is telling us, come back to this\n",
    "#maybe we've got like four-ish groups here, but it's not clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd218e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_feature(tokens):\n",
    "    feats={}\n",
    "    for word in tokens:\n",
    "        feats[\"UNIGRAM_%s\" % word]=1\n",
    "    return feats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anlp] *",
   "language": "python",
   "name": "conda-env-anlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
