{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from lexicalrichness import LexicalRichness\n",
    "import textstat\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import wald\n",
    "from scipy.stats import mannwhitneyu\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath2= os.path.dirname(os.path.dirname(os.getcwd()))+\"\\\\Data\\\\Intermediate Data\\\\\"\n",
    "df=pd.read_csv(inpath2+'final_all_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_len']=df['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mattr'] = df['text'].apply(lambda x: LexicalRichness(x).mattr(window_size=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FK']=df['text'].apply(lambda x: textstat.flesch_kincaid_grade(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    return nltk.word_tokenize(data)\n",
    "def get_counts(tokens):\n",
    "    counts=Counter()\n",
    "    for token in tokens:\n",
    "        counts[token]+=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tc(testText): \n",
    "    tokens=tokenize(testText)\n",
    "    token_counts=get_counts(tokens)\n",
    "    freq_df=pd.DataFrame.from_dict(token_counts, orient='index', columns=['frequency']).reset_index().sort_values(by='frequency', ascending=False)\n",
    "    freq_df['x']=1\n",
    "    freq_df['rank']=freq_df.groupby('x').cumcount()+1\n",
    "    fr1=freq_df.iloc[0,1]\n",
    "    fr2=freq_df.iloc[1,1]\n",
    "    r1=freq_df.iloc[0,3]\n",
    "    r2=freq_df.iloc[1,3]\n",
    "    h_point=((fr1*r2)-(fr2*r1))/(r2-r1+fr1-fr2)\n",
    "    freq_df['TW']=np.where(freq_df['rank']<h_point, 2*(((h_point-freq_df['rank'])*(freq_df['frequency']))/((h_point*(h_point-1)*fr1))), 0)\n",
    "    return freq_df['TW'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TC']=df['text'].apply(lambda x: calculate_tc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump=df[df['candidate']=='trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcrrt\\AppData\\Local\\Temp/ipykernel_20028/3625745240.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trump['rally']=np.where(trump['event_type']=='rally', 1, 0)\n"
     ]
    }
   ],
   "source": [
    "trump['rally']=np.where(trump['event_type']=='rally', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_rallies=trump[trump['rally']==1]\n",
    "trump_not_rallies=trump[trump['rally']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.1226434765155002, pvalue=0.2627954556521124)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(trump_rallies.TC, trump_not_rallies.TC, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=5446.5, pvalue=0.028287041805636834)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(trump_rallies.TC, trump_not_rallies.TC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.5213342215547009, pvalue=0.602683910198359)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(trump_rallies.FK, trump_not_rallies.FK, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=3184.0, pvalue=3.67446677801599e-11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(trump_rallies.FK, trump_not_rallies.FK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-13.357719864481169, pvalue=2.606497694844693e-29)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_ind(trump_rallies.mattr, trump_not_rallies.mattr, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=1110.5, pvalue=3.7043903298640934e-27)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(trump_rallies.mattr, trump_not_rallies.mattr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">mattr</th>\n",
       "      <th colspan=\"5\" halign=\"left\">TC</th>\n",
       "      <th colspan=\"8\" halign=\"left\">FK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rally</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.0</td>\n",
       "      <td>0.852888</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>0.814184</td>\n",
       "      <td>0.840418</td>\n",
       "      <td>0.850485</td>\n",
       "      <td>0.864273</td>\n",
       "      <td>0.904532</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.692803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799161</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>112.0</td>\n",
       "      <td>270.036607</td>\n",
       "      <td>797.267424</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4190.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.824522</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.802451</td>\n",
       "      <td>0.817030</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>0.828617</td>\n",
       "      <td>0.888349</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.669341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777531</td>\n",
       "      <td>0.892642</td>\n",
       "      <td>114.0</td>\n",
       "      <td>335.015789</td>\n",
       "      <td>1060.199711</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5945.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mattr                                                              \\\n",
       "       count      mean       std       min       25%       50%       75%   \n",
       "rally                                                                      \n",
       "0      112.0  0.852888  0.018664  0.814184  0.840418  0.850485  0.864273   \n",
       "1      114.0  0.824522  0.012630  0.802451  0.817030  0.823022  0.828617   \n",
       "\n",
       "                    TC            ...                         FK              \\\n",
       "            max  count      mean  ...       75%       max  count        mean   \n",
       "rally                             ...                                          \n",
       "0      0.904532  112.0  0.692803  ...  0.799161  0.912281  112.0  270.036607   \n",
       "1      0.888349  114.0  0.669341  ...  0.777531  0.892642  114.0  335.015789   \n",
       "\n",
       "                                                \n",
       "               std  min  25%  50%  75%     max  \n",
       "rally                                           \n",
       "0       797.267424  1.7  5.0  6.4  8.9  4190.7  \n",
       "1      1060.199711  3.6  4.0  4.5  5.4  5945.3  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.groupby('rally')[['mattr', 'TC', 'FK']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rally     114\n",
       "speech    109\n",
       "debate      3\n",
       "Name: event_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only certain frequencies, stop words - LIWC - 70-80 features. Mispelled - not going to be able to find it\n",
    "#topic modeling - dimensionality reduction\n",
    "#most relevant words for each topic - give an identity to each topic - topic modeling to predict features for each\n",
    "#5 topics - how prominent the topic is within the document = use that score as the feature - almost 30 x 5 - good row to column ratio\n",
    "#For every feature - 6 rows - \n",
    "#sequence embedding for each speech - could cluster - look for certain outliers - one particular rally speech\n",
    "#visualize in a two d pot\n",
    "#t-ste - condense to two-d ste - interactive 2-d scatter plot - certain keywords\n",
    "#pattern you can see from the sequence embeddings - color the dots - see that the red dots - \n",
    "#bert topic modeling \n",
    "#tfid - word threshold - top 1000 words - LIWC version - convert every word to LIWC features\n",
    "#ngram=(2,2) - bigrams, max_df - do not only include words show up in 50% or fewer documents - 200 documents or less.\n",
    "#min_df - only tokenize words that show up in at least 5 documents\n",
    "#max_features - only 1000 most popular words! \n",
    "#binary - if word in the document or not\n",
    "#tfid - see words that bring value - stop words - show up in many different documents\n",
    "#low tfid - stopwords - are not labeled stopwords - find a way to help reduce the number of tokens - pass that into tfid\n",
    "#once you fit tfidf - find the tokens that have a high tf-idf.\n",
    "#hate speech/dehumanization - \n",
    "#https://towardsdatascience.com/kl-divergence-python-example-b87069e4b810\n",
    "#https://towardsdatascience.com/interactive-topic-modeling-with-bertopic-1ea55e7d73d8\n",
    "#https://cs.stanford.edu/people/wmorgan/sigtest.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
